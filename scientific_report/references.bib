@article{Chavas2015,
author = {Chavas, Jean-Paul and Shi, Guanming},
file = {:C$\backslash$:/Users/Ariel/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chavas, Shi - 2015 - An Economic Analysis of Risk, Management, and Agricultural Technology.pdf:pdf},
journal = {Journal of Agricultural and Resource Economics},
keywords = {Agribusiness,Research and Development/Tech Change/Emerging Tech,Risk and Uncertainty,certainty equivalente,premium risk},
mendeley-groups = {Risk Analysis},
mendeley-tags = {certainty equivalente,premium risk},
number = {1},
pages = {63--79},
publisher = {Western Agricultural Economics Association},
title = {{An Economic Analysis of Risk, Management, and Agricultural Technology}},
volume = {40},
year = {2015}
}


@misc{wu2020todbert,
    title={ToD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogues},
    author={Chien-Sheng Wu and Steven Hoi and Richard Socher and Caiming Xiong},
    year={2020},
    eprint={2004.06871},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{sellam2020bleurt,
    title={BLEURT: Learning Robust Metrics for Text Generation},
    author={Thibault Sellam and Dipanjan Das and Ankur P. Parikh},
    year={2020},
    eprint={2004.04696},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{zhao2017learning,
    title={Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders},
    author={Tiancheng Zhao and Ran Zhao and Maxine Eskenazi},
    year={2017},
    eprint={1703.10960},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{devlin2018bert,
    title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
    year={2018},
    eprint={1810.04805},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{devlin2018bert,
    title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
    year={2018},
    eprint={1810.04805},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{liu2019roberta,
    title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
    author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
    year={2019},
    eprint={1907.11692},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{mehri2020usr,
    title={USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation},
    author={Shikib Mehri and Maxine Eskenazi},
    year={2020},
    eprint={2005.00456},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{wang2018glue,
    title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
    author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
    year={2018},
    eprint={1804.07461},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{clark2020electra,
    title={ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators},
    author={Kevin Clark and Minh-Thang Luong and Quoc V. Le and Christopher D. Manning},
    year={2020},
    eprint={2003.10555},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{yang2019xlnet,
    title={XLNet: Generalized Autoregressive Pretraining for Language Understanding},
    author={Zhilin Yang and Zihang Dai and Yiming Yang and Jaime Carbonell and Ruslan Salakhutdinov and Quoc V. Le},
    year={2019},
    eprint={1906.08237},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{vaswani2017attention,
    title={Attention Is All You Need},
    author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
    year={2017},
    eprint={1706.03762},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{Gao2020,
    title={Paraphrase Augmented Task-Oriented Dialog Generation},
    author={Silin Gao and Yichi Zhang and Zhijian Ou and Zhou Yu},
    year={2020},
    eprint={2004.07462},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{chen2019semantically,
    title={Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention},
    author={Wenhu Chen and Jianshu Chen and Pengda Qin and Xifeng Yan and William Yang Wang},
    year={2019},
    eprint={1905.12866},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{budzianowski-etal-2018-multiwoz,
    title = "{M}ulti{WOZ} - A Large-Scale Multi-Domain Wizard-of-{O}z Dataset for Task-Oriented Dialogue Modelling",
    author = "Budzianowski, Pawe{\l}  and
      Wen, Tsung-Hsien  and
      Tseng, Bo-Hsiang  and
      Casanueva, I{\~n}igo  and
      Ultes, Stefan  and
      Ramadan, Osman  and
      Ga{\v{s}}i{\'c}, Milica",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1547",
    doi = "10.18653/v1/D18-1547",
    pages = "5016--5026",
}


@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@misc{vaswani2017attention,
    title={Attention Is All You Need},
    author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
    year={2017},
    eprint={1706.03762},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{devlin2018bert,
    title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
    year={2018},
    eprint={1810.04805},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{peng2020fewshot,
    title={Few-shot Natural Language Generation for Task-Oriented Dialog},
    author={Baolin Peng and Chenguang Zhu and Chunyuan Li and Xiujun Li and Jinchao Li and Michael Zeng and Jianfeng Gao},
    year={2020},
    eprint={2002.12328},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{Kale2020,
    title={Few-Shot Natural Language Generation by Rewriting Templates},
    author={Mihir Kale and Abhinav Rastogi},
    year={2020},
    eprint={2004.15006},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{Hardaker2004,
author = {Hardaker, J. Brian and Richardson, James W. and Lien, Gudbrand and Schumann, Keith D.},
doi = {10.1111/j.1467-8489.2004.00239.x},
issn = {1364-985X},
journal = {The Australian Journal of Agricultural and Resource Economics},
keywords = {SERF,certainty equivalente,premium risk},
mendeley-groups = {Risk Analysis},
mendeley-tags = {SERF,certainty equivalente,premium risk},
month = {6},
number = {2},
pages = {253--270},
publisher = {John Wiley {\&} Sons, Ltd (10.1111)},
title = {{Stochastic efficiency analysis with risk aversion bounds: a simplified approach}},
volume = {48},
year = {2004}
}


@article{zhang2019bertscore,
  title={Bertscore: Evaluating text generation with bert},
  author={Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
  journal={arXiv preprint arXiv:1904.09675},
  year={2019}
}


@misc{Zhelezniak:2019,
    title={Correlations between Word Vector Sets},
    author={Vitalii Zhelezniak and April Shen and Daniel Busbridge and Aleksandar Savkov and Nils Hammerla},
    year={2019},
    eprint={1910.02902},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{wen-etal-2015-semantically,
    title = "Semantically Conditioned {LSTM}-based Natural Language Generation for Spoken Dialogue Systems",
    author = "Wen, Tsung-Hsien  and
      Ga{\v{s}}i{\'c}, Milica  and
      Mrk{\v{s}}i{\'c}, Nikola  and
      Su, Pei-Hao  and
      Vandyke, David  and
      Young, Steve",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D15-1199",
    doi = "10.18653/v1/D15-1199",
    pages = "1711--1721",
}


@article{Kingma:2019,
  author    = {Diederik P. Kingma and
               Max Welling},
  title     = {An Introduction to Variational Autoencoders},
  journal   = {CoRR},
  volume    = {abs/1906.02691},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.02691},
  archivePrefix = {arXiv},
  eprint    = {1906.02691},
  timestamp = {Thu, 13 Jun 2019 13:36:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-02691.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lee-etal-2019-sumbt,
    title = "{SUMBT}: Slot-Utterance Matching for Universal and Scalable Belief Tracking",
    author = "Lee, Hwaran  and
      Lee, Jinsik  and
      Kim, Tae-Yoon",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1546",
    doi = "10.18653/v1/P19-1546",
    pages = "5478--5483",
    abstract = "In goal-oriented dialog systems, belief trackers estimate the probability distribution of slot-values at every dialog turn. Previous neural approaches have modeled domain- and slot-dependent belief trackers, and have difficulty in adding new slot-values, resulting in lack of flexibility of domain ontology configurations. In this paper, we propose a new approach to universal and scalable belief tracker, called slot-utterance matching belief tracker (SUMBT). The model learns the relations between domain-slot-types and slot-values appearing in utterances through attention mechanisms based on contextual semantic vectors. Furthermore, the model predicts slot-value labels in a non-parametric way. From our experiments on two dialog corpora, WOZ 2.0 and MultiWOZ, the proposed model showed performance improvement in comparison with slot-dependent methods and achieved the state-of-the-art joint accuracy.",
}

@misc{qiu2020pretrained,
    title={Pre-trained Models for Natural Language Processing: A Survey},
    author={Xipeng Qiu and Tianxiang Sun and Yige Xu and Yunfan Shao and Ning Dai and Xuanjing Huang},
    year={2020},
    eprint={2003.08271},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{schmidt2020bert,
    title={BERT as a Teacher: Contextual Embeddings for Sequence-Level Reward},
    author={Florian Schmidt and Thomas Hofmann},
    year={2020},
    eprint={2003.02738},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{madotto2020attention,
    title={Attention over Parameters for Dialogue Systems},
    author={Andrea Madotto and Zhaojiang Lin and Chien-Sheng Wu and Jamin Shin and Pascale Fung},
    year={2020},
    eprint={2001.01871},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{wang2020efficient,
    title={Efficient Sentence Embedding via Semantic Subspace Analysis},
    author={Bin Wang and Fenxiao Chen and Yuncheng Wang and C. -C. Jay Kuo},
    year={2020},
    eprint={2002.09620},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{wen2015semantically,
  title={Semantically conditioned lstm-based natural language generation for spoken dialogue systems},
  author={Wen, Tsung-Hsien and Gasic, Milica and Mrksic, Nikola and Su, Pei-Hao and Vandyke, David and Young, Steve},
  journal={arXiv preprint arXiv:1508.01745},
  year={2015}
}

@misc{heck2020trippy,
    title={TripPy: A Triple Copy Strategy for Value Independent Neural Dialog State Tracking},
    author={Michael Heck and Carel van Niekerk and Nurul Lubis and Christian Geishauser and Hsien-Chin Lin and Marco Moresi and Milica Gašić},
    year={2020},
    eprint={2005.02877},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{wen-etal-2017-network,
    title = "A Network-based End-to-End Trainable Task-oriented Dialogue System",
    author = "Wen, Tsung-Hsien  and
      Vandyke, David  and
      Mrk{\v{s}}i{\'c}, Nikola  and
      Ga{\v{s}}i{\'c}, Milica  and
      Rojas-Barahona, Lina M.  and
      Su, Pei-Hao  and
      Ultes, Stefan  and
      Young, Steve",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/E17-1042",
    pages = "438--449",
    abstract = "Teaching machines to accomplish tasks by conversing naturally with humans is challenging. Currently, developing task-oriented dialogue systems requires creating multiple components and typically this involves either a large amount of handcrafting, or acquiring costly labelled datasets to solve a statistical learning problem for each component. In this work we introduce a neural network-based text-in, text-out end-to-end trainable goal-oriented dialogue system along with a new way of collecting dialogue data based on a novel pipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue systems easily and without making too many assumptions about the task at hand. The results show that the model can converse with human subjects naturally whilst helping them to accomplish tasks in a restaurant search domain.",
}


@misc{cai2020learning,
    title={Learning from Easy to Complex: Adaptive Multi-curricula Learning for Neural Dialogue Generation},
    author={Hengyi Cai and Hongshen Chen and Cheng Zhang and Yonghao Song and Xiaofang Zhao and Yangxi Li and Dongsheng Duan and Dawei Yin},
    year={2020},
    eprint={2003.00639},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{zeng2020style,
    title={Style Example-Guided Text Generation using Generative Adversarial Transformers},
    author={Kuo-Hao Zeng and Mohammad Shoeybi and Ming-Yu Liu},
    year={2020},
    eprint={2003.00674},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
@misc{grohe2020word2vec,
    title={word2vec, node2vec, graph2vec, X2vec: Towards a Theory of Vector Embeddings of Structured Data},
    author={Martin Grohe},
    year={2020},
    eprint={2003.12590},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{yin2020metacotgan,
    title={Meta-CoTGAN: A Meta Cooperative Training Paradigm for Improving Adversarial Text Generation},
    author={Haiyan Yin and Dingcheng Li and Xu Li and Ping Li},
    year={2020},
    eprint={2003.11530},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{adewumi2020word2vec,
    title={Word2Vec: Optimal Hyper-Parameters and Their Impact on NLP Downstream Tasks},
    author={Tosin P. Adewumi and Foteini Liwicki and Marcus Liwicki},
    year={2020},
    eprint={2003.11645},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{yang2019xlnet,
    title={XLNet: Generalized Autoregressive Pretraining for Language Understanding},
    author={Zhilin Yang and Zihang Dai and Yiming Yang and Jaime Carbonell and Ruslan Salakhutdinov and Quoc V. Le},
    year={2019},
    eprint={1906.08237},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@article{Witteveen_2019,
   title={Paraphrasing with Large Language Models},
   url={http://dx.doi.org/10.18653/v1/D19-5623},
   DOI={10.18653/v1/d19-5623},
   journal={Proceedings of the 3rd Workshop on Neural Generation and Translation},
   publisher={Association for Computational Linguistics},
   author={Witteveen, Sam and Andrews, Martin},
   year={2019}
}

@misc{wu2018conditional,
    title={Conditional BERT Contextual Augmentation},
    author={Xing Wu and Shangwen Lv and Liangjun Zang and Jizhong Han and Songlin Hu},
    year={2018},
    eprint={1812.06705},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{pavlick-etal-2015-ppdb,
    title = "{PPDB} 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification",
    author = "Pavlick, Ellie  and
      Rastogi, Pushpendre  and
      Ganitkevitch, Juri  and
      Van Durme, Benjamin  and
      Callison-Burch, Chris",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P15-2070",
    doi = "10.3115/v1/P15-2070",
    pages = "425--430",
}

@inproceedings{madnani2012re,
  title={Re-examining machine translation metrics for paraphrase identification},
  author={Madnani, Nitin and Tetreault, Joel and Chodorow, Martin},
  booktitle={Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={182--190},
  year={2012},
  organization={Association for Computational Linguistics}
}
@misc{zhang2019paws,
    title={PAWS: Paraphrase Adversaries from Word Scrambling},
    author={Yuan Zhang and Jason Baldridge and Luheng He},
    year={2019},
    eprint={1904.01130},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{van-der-lee-etal-2019-best,
    title = "Best practices for the human evaluation of automatically generated text",
    author = "van der Lee, Chris  and
      Gatt, Albert  and
      van Miltenburg, Emiel  and
      Wubben, Sander  and
      Krahmer, Emiel",
    booktitle = "Proceedings of the 12th International Conference on Natural Language Generation",
    month = oct # "{--}" # nov,
    year = "2019",
    address = "Tokyo, Japan",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-8643",
    doi = "10.18653/v1/W19-8643",
    pages = "355--368",
    abstract = "Currently, there is little agreement as to how Natural Language Generation (NLG) systems should be evaluated. While there is some agreement regarding automatic metrics, there is a high degree of variation in the way that human evaluation is carried out. This paper provides an overview of how human evaluation is currently conducted, and presents a set of best practices, grounded in the literature. With this paper, we hope to contribute to the quality and consistency of human evaluations in NLG.",
}

@article{Wolf2019HuggingFacesTS,
  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.03771}
}

@inproceedings{papineni2002bleu,
  title={BLEU: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}


@misc{vaswani2017attention,
    title={Attention Is All You Need},
    author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
    year={2017},
    eprint={1706.03762},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


@article{bengio1994learning,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
  journal={IEEE transactions on neural networks},
  volume={5},
  number={2},
  pages={157--166},
  year={1994},
  publisher={IEEE}
}


@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}


@inproceedings{stent2005,
  title={Evaluating evaluation methods for generation in the presence of variation},
  author={Stent, Amanda and Marge, Matthew and Singhai, Mohit},
  booktitle={international conference on intelligent text processing and computational linguistics},
  pages={341--351},
  year={2005},
  organization={Springer}
}


@inproceedings{banerjee2005,
    title = "{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments",
    author = "Banerjee, Satanjeev  and
      Lavie, Alon",
    booktitle = "Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
    month = jun,
    year = "2005",
    address = "Ann Arbor, Michigan",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W05-0909",
    pages = "65--72",
}

@inproceedings{Papineni2002,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
title = {BLEU: A Method for Automatic Evaluation of Machine Translation},
year = {2002},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1073083.1073135},
doi = {10.3115/1073083.1073135},
abstract = {Human evaluations of machine translation are extensive but expensive. Human evaluations can take months to finish and involve human labor that can not be reused. We propose a method of automatic machine translation evaluation that is quick, inexpensive, and language-independent, that correlates highly with human evaluation, and that has little marginal cost per run. We present this method as an automated understudy to skilled human judges which substitutes for them when there is need for quick or frequent evaluations.},
booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
pages = {311–318},
numpages = {8},
location = {Philadelphia, Pennsylvania},
series = {ACL '02}
}

  

@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W04-1013",
    pages = "74--81",
}


@inproceedings{ritter2011data,
  title={Data-driven response generation in social media},
  author={Ritter, Alan and Cherry, Colin and Dolan, William B},
  booktitle={Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing},
  pages={583--593},
  year={2011}
}
