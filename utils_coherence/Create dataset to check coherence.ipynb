{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from utils import nlp\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import shuffle, sample\n",
    "random.seed(30)\n",
    "from collections import Counter\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliar functions\n",
    "def slice_keys(key_list, proportion=0.3):\n",
    "    return list(key_list)[:int(len(key_list) * proportion)]\n",
    "\n",
    "def scramble(sentence):\n",
    "    split = sentence.split()  # Split the string into a list of words\n",
    "    shuffle(split)  # This shuffles the list in-place.\n",
    "    return ' '.join(split)  # Turn the list back into a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset for Language Modeling GPT\n",
    "Using the Multiwoz dataset to fine tuning gpt model to generate syntetic utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_base_dir = '../MultiWOZ_2.1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mw_base_dir + 'valListFile.txt', 'r') as fp:\n",
    "    val_list = fp.readlines()\n",
    "    val_list = [elem.strip() for elem in val_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(mw_base_dir + 'testListFile.txt', 'r') as fp:\n",
    "    test_list = fp.readlines()\n",
    "    test_list = [elem.strip() for elem in test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mw_data = json.load(open(mw_base_dir + 'data.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = set(mw_data.keys()) - set(test_list) - set(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_lm_rnn(keys, filename):\n",
    "    examples = []\n",
    "    for key in keys:\n",
    "        data = mw_data[key]['log']\n",
    "        for i in range(0, len(data), 2):\n",
    "            sys = data[i + 1]['text']\n",
    "            examples.append(nlp.normalize(sys))\n",
    "    with open(filename+'.txt', 'w') as f:\n",
    "        for item in examples:\n",
    "            f.write(\"%s \\n\" % item)\n",
    "    \n",
    "def generate_dataset_lm(keys, filename, add_label=False):\n",
    "    examples = []\n",
    "    for key in keys:\n",
    "        data = mw_data[key]['log']\n",
    "        for i in range(0, len(data), 2):\n",
    "            sys = data[i + 1]['text']\n",
    "            if add_label:\n",
    "                examples.append((nlp.normalize(sys), '1'))\n",
    "            else:\n",
    "                examples.append(nlp.normalize(sys))\n",
    "    with open(filename+'_lm.raw', 'w') as f:\n",
    "        for item in examples:\n",
    "            f.write(\"%s <|endoftext|> \\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset_lm(train_list, 'train')\n",
    "#generate_dataset_lm(val_list, 'valid')\n",
    "#generate_dataset_lm(test_list, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre process the utterances generated by SC-GPT\n",
    "Extract the results from sc-gpt to calculate the coherence of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = json.load(open('multiwoz.pred.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for key in train_list:\n",
    "    data = mw_data[key]['log']\n",
    "    for i in range(0, len(data), 2):\n",
    "        sys = data[i + 1]['text']\n",
    "        test.append((nlp.normalize(sys).replace('\"', ''), '1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_utt = []\n",
    "for examples in pred:\n",
    "    utt = examples[0]\n",
    "    cl_idx = utt.find('<|endoftext|>')\n",
    "    utt = utt[:cl_idx].strip().lower()\n",
    "    gen_utt.append((nlp.normalize(utt), '0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gen_utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(gen_utt + test)\n",
    "df.columns = ['text', 'label']\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('mw_sc_gpt_mixed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate examples for Binary classification GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_gen_train = json.load(open('lm_gpt/gpt_generated_train.json'))\n",
    "gpt_gen_test = json.load(open('lm_gpt/gpt_generated_test.json'))\n",
    "gpt_gen_valid = json.load(open('lm_gpt/gpt_generated_valid.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_gen_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD DATASET FOR COHERENCE CLASSIFICATION\n",
    "train = []\n",
    "for key in val_list:\n",
    "    data = mw_data[key]['log']\n",
    "    for i in range(0, len(data), 2):\n",
    "        sys = data[i + 1]['text']\n",
    "        train.append((nlp.normalize(sys).replace('\"', ''), '1'))\n",
    "        #train.append((scramble(nlp.normalize(sys)), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lite = []\n",
    "for elem in gpt_gen_valid:\n",
    "    idx = elem.find('<|endoftext|>')\n",
    "    if idx != -1:\n",
    "        elem = elem[:idx]\n",
    "    lite.append((nlp.normalize(elem).replace('\"', ''), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train += lite + random.sample(lite, 221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(train, columns=['text','label'])\n",
    "df.to_csv('valid_bert_gpt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate examples for Binary classification Transformer based LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_trans = 'lm_transformer/'\n",
    "fin = open(base_trans + 'valid_transformer.txt', 'r')\n",
    "data = fin.read()\n",
    "trans_data = data.split('<eos>')\n",
    "trans_data = [elem.replace('\\n', ' ').strip() for elem in trans_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8781"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data = [w for w in trans_data if len(w.split()) > 2]\n",
    "trans_data = trans_data[:7374]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for key in val_list:\n",
    "    data = mw_data[key]['log']\n",
    "    for i in range(0, len(data), 2):\n",
    "        sys = data[i + 1]['text']\n",
    "        train.append((nlp.normalize(sys).replace('\"', ''), '1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7374"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trans_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in trans_data:\n",
    "    train.append((nlp.normalize(elem), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14748"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train, columns=['text','label'])\n",
    "df = df.sample(frac=1)\n",
    "df.to_csv('valid_bert_transformer.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate examples for Binary classification LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lstm = 'lm_lstm/'\n",
    "fin = open(base_lstm + 'generated_lstm_valid.txt', 'r')\n",
    "data = fin.read()\n",
    "lstm_data = data.split('<eos>')\n",
    "lstm_data = [elem.replace('\\n', ' ').strip() for elem in lstm_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lstm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_data = lstm_data[:7374]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for key in val_list:\n",
    "    data = mw_data[key]['log']\n",
    "    for i in range(0, len(data), 2):\n",
    "        sys = data[i + 1]['text']\n",
    "        train.append((nlp.normalize(sys).replace('\"', ''), '1'))\n",
    "        #train.append((scramble(nlp.normalize(sys)), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in lstm_data:\n",
    "    train.append((nlp.normalize(elem), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train, columns=['text','label'])\n",
    "df = df.sample(frac=1)\n",
    "df.to_csv('valid_bert_lstm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate examples mixing GPT and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_gen_train = json.load(open('lm_gpt/gpt_generated_train.json'))\n",
    "gpt_gen_test = json.load(open('lm_gpt/gpt_generated_test.json'))\n",
    "gpt_gen_valid = json.load(open('lm_gpt/gpt_generated_valid.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lite = []\n",
    "for elem in gpt_gen_valid:\n",
    "    idx = elem.find('<|endoftext|>')\n",
    "    if idx != -1:\n",
    "        elem = elem[:idx]\n",
    "    lite.append((nlp.normalize(elem).replace('\"', ''), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lstm = 'lm_lstm/'\n",
    "fin = open(base_lstm + 'generated_valid.txt', 'r')\n",
    "data = fin.read()\n",
    "lstm_data = data.split('<eos>')\n",
    "lstm_data = [elem.replace('\\n', ' ').strip() for elem in lstm_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm = []\n",
    "for elem in lstm_data:\n",
    "    train_lstm.append((nlp.normalize(elem), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = train + train_lstm[:3687] + lite[:3687]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(full, columns=['text','label'])\n",
    "df = df.sample(frac=1)\n",
    "df.to_csv('valid_bert_lstm_gpt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate examples mixing LSTM GPT TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT LM\n",
    "gpt_gen_train = json.load(open('lm_gpt/gpt_generated_train.json'))\n",
    "gpt_gen_test = json.load(open('lm_gpt/gpt_generated_test.json'))\n",
    "gpt_gen_valid = json.load(open('lm_gpt/gpt_generated_valid.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM language model\n",
    "base_lstm = 'lm_lstm/'\n",
    "fin = open(base_lstm + 'generated_lstm_valid.txt', 'r')\n",
    "data = fin.read()\n",
    "lstm_data = data.split('<eos>')\n",
    "lstm_data = [elem.replace('\\n', ' ').strip() for elem in lstm_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers LM\n",
    "base_trans = 'lm_transformer/'\n",
    "fin = open(base_trans + 'valid_generated_transformer.txt', 'r')\n",
    "data = fin.read()\n",
    "trans_data = data.split('<eos>')\n",
    "trans_data = [elem.replace('\\n', ' ').strip() for elem in trans_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = random.sample(trans_data, 2458) + random.sample(gpt_gen_train, 2458) + random.sample(trans_data, 2458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTIWOZ\n",
    "train = []\n",
    "for key in val_list:\n",
    "    data = mw_data[key]['log']\n",
    "    for i in range(0, len(data), 2):\n",
    "        sys = data[i + 1]['text']\n",
    "        train.append((nlp.normalize(sys).replace('\"', ''), '1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7374"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7372"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in train_2:\n",
    "    train.append((nlp.normalize(elem), '0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7374"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train, columns=['text','label'])\n",
    "df = df.sample(frac=1)\n",
    "df.to_csv('valid_bert_mixed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most frequent prompts system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for key in train_list:\n",
    "    data = mw_data[key]['log']\n",
    "    for i in range(0, len(data), 2):\n",
    "        sys = data[i + 1]['text']\n",
    "        train.append((nlp.normalize(sys), '1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train)\n",
    "df = df.rename(columns={0:'text', 1:'label'})\n",
    "df['prompts'] = df.text.map(lambda x: ' '.join(x.split()[:2]))\n",
    "df = df.groupby('prompts').count().sort_values('label', ascending=False).reset_index()\n",
    "df.drop(df[['text','label']], axis=1, inplace=True)\n",
    "newdf = pd.DataFrame(np.repeat(df.values,14,axis=0))\n",
    "newdf.columns = df.columns\n",
    "newdf = newdf.sample(frac=1)\n",
    "newdf.to_csv('prompts_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDSA Lexicalization to calculate the coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('hdsa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdsa_test = json.load(open('hdsa/test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dacts = {}\n",
    "for elem in hdsa_test:\n",
    "    diag_list = [] \n",
    "    for turn in elem['info']:\n",
    "        diag_list.append(turn['act'])\n",
    "    dacts[elem['file']] = diag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_hdsa = json.load(open('hdsa/results.txt.pred.BERT_dim128_w_domain.pred'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacements like hotels => hotel -s\n",
    "fin = open('hdsa/mapping.pair')\n",
    "replacements = []\n",
    "for line in fin.readlines():\n",
    "    tok_from, tok_to = line.replace('\\n', '').split('\\t')\n",
    "    replacements.append((' ' + tok_from + ' ', ' ' + tok_to + ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_acts = {}\n",
    "value_count = '[value_count]'\n",
    "for fname, lst_dact in dacts.items():\n",
    "    list_dact = []\n",
    "    for dact in lst_dact:\n",
    "        formatted_da = {}\n",
    "        for slot, value in dact.items():\n",
    "            if slot.split('-')[-1] == 'choice':\n",
    "                formatted_da[value_count] = value\n",
    "            elif value != 'none' and value != '?':\n",
    "                key = '['+ slot.split('-')[0] + '_' + slot.split('-')[-1] + ']'\n",
    "                for fromx, tox in replacements:\n",
    "                    value = ' ' + value + ' '\n",
    "                    value = value.replace(fromx, tox)[1:-1]\n",
    "                formatted_da[key] = value\n",
    "        list_dact.append(formatted_da)\n",
    "    dialogue_acts[fname] = list_dact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the formated dialogue acts slot value into the utterances\n",
    "cleaned = []\n",
    "for fname, utts in generated_hdsa.items():\n",
    "    for utterance, das in zip(utts, dialogue_acts[fname]):\n",
    "        for slot, value in das.items():\n",
    "            utterance = utterance.replace(slot, value)\n",
    "        cleaned.append((utterance, '1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdsa_df = pd.DataFrame(cleaned, columns=['text','label'])\n",
    "\n",
    "hdsa_df.to_csv('test_hdsa.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
